{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../tools')\n",
    "\n",
    "from monodepth2.infer import load_model\n",
    "from fps_utils import run_first_phase_model\n",
    "from tracktor_utils import tracker_obj\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = './samples/mot16.webm' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monodepth FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading model from  models/mono+stereo_1024x320\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n"
     ]
    }
   ],
   "source": [
    "inference = {'name': 'monodepth'}\n",
    "\n",
    "encoder, depth_decoder, (feed_width, feed_height) = load_model(\"mono+stereo_1024x320\")\n",
    "inference['encoder'] = encoder\n",
    "inference['depth_decoder'] = depth_decoder\n",
    "inference['input_size'] = (feed_width, feed_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    run_first_phase_model(frame, inference)\n",
    "    \n",
    "duration = time.time() - start\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame Size: 540x960\n",
      "FPS: 21.85879561908524\n"
     ]
    }
   ],
   "source": [
    "monodepth_fps = n_frames / duration\n",
    "\n",
    "print(f\"frame Size: {h}x{w}\\nFPS: {monodepth_fps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mannequin FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mannequinchallenge.infer import infer_depth as mannequin_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================  DIW NETWORK TRAIN FROM Ours_Bilinear=======================\n",
      "===================Loading Pretrained Model OURS ===================================\n",
      "./monoculardepth/mannequinchallenge/checkpoints/test_local/best_depth_Ours_Bilinear_inc_3_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): HourglassModel(\n",
      "    (seq): Sequential(\n",
      "      (0): Conv2d(3, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Channels4(\n",
      "        (list): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "            (1): inception[[32], [3, 32, 32], [5, 32, 32], [7, 32, 32]]\n",
      "            (2): inception[[32], [3, 32, 32], [5, 32, 32], [7, 32, 32]]\n",
      "            (3): Channels3(\n",
      "              (list): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "                  (1): inception[[32], [3, 32, 32], [5, 32, 32], [7, 32, 32]]\n",
      "                  (2): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                  (3): Channels2(\n",
      "                    (list): ModuleList(\n",
      "                      (0): Sequential(\n",
      "                        (0): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                        (1): inception[[64], [3, 64, 64], [7, 64, 64], [11, 64, 64]]\n",
      "                      )\n",
      "                      (1): Sequential(\n",
      "                        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "                        (1): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                        (2): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                        (3): Channels1(\n",
      "                          (list): ModuleList(\n",
      "                            (0): Sequential(\n",
      "                              (0): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                              (1): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                            )\n",
      "                            (1): Sequential(\n",
      "                              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "                              (1): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                              (2): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                              (3): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                              (4): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "                            )\n",
      "                          )\n",
      "                        )\n",
      "                        (4): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                        (5): inception[[64], [3, 64, 64], [7, 64, 64], [11, 64, 64]]\n",
      "                        (6): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (4): inception[[64], [3, 32, 64], [5, 32, 64], [7, 32, 64]]\n",
      "                  (5): inception[[32], [3, 32, 32], [5, 32, 32], [7, 32, 32]]\n",
      "                  (6): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): inception[[32], [3, 32, 32], [5, 32, 32], [7, 32, 32]]\n",
      "                  (1): inception[[32], [3, 64, 32], [7, 64, 32], [11, 64, 32]]\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (4): inception[[32], [3, 64, 32], [5, 64, 32], [7, 64, 32]]\n",
      "            (5): inception[[16], [3, 32, 16], [7, 32, 16], [11, 32, 16]]\n",
      "            (6): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): inception[[16], [3, 64, 16], [7, 64, 16], [11, 64, 16]]\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (uncertainty_layer): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (pred_layer): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 5357730\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# dummy image for initial loading\n",
    "run_first_phase_model(np.random.randint(255, size=(900,800,3),dtype=np.uint8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    run_first_phase_model(frame)\n",
    "    \n",
    "duration = time.time() - start\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame Size: 540x960\n",
      "FPS: 5.656180823425704\n"
     ]
    }
   ],
   "source": [
    "mannequin_fps = n_frames / duration\n",
    "\n",
    "print(f\"frame Size: {h}x{w}\\nFPS: {mannequin_fps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation/Object Tracking Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fps_utils import run_second_phase_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLACT FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading model from  models/yolact_plus_resnet50_54_800000.pth\n",
      "   Loading pretrained model\n"
     ]
    }
   ],
   "source": [
    "# dummy image for initial loading\n",
    "run_second_phase_model(np.random.randint(255, size=(900,800,3),dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    run_second_phase_model(frame)\n",
    "    \n",
    "duration = time.time() - start\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame Size: 540x960\n",
      "FPS: 5.845065278487446\n"
     ]
    }
   ],
   "source": [
    "yolact_fps = n_frames / duration\n",
    "\n",
    "print(f\"frame Size: {h}x{w}\\nFPS: {yolact_fps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracker FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = tracker_obj(\"./tracking_wo_bnw\")\n",
    "tracker.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    run_second_phase_model(frame, tracker)\n",
    "    \n",
    "duration = time.time() - start\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame Size: 540x960\n",
      "FPS: 2.7322334210962897\n"
     ]
    }
   ],
   "source": [
    "tracker_fps = n_frames / duration\n",
    "\n",
    "print(f\"frame Size: {h}x{w}\\nFPS: {tracker_fps}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 PLARR",
   "language": "python",
   "name": "plarr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
